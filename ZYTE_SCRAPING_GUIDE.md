# ğŸ•·ï¸ Zyte (Scrapy Cloud) - Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

## ğŸ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ Ù…Ù† GitHub Student Pack

```
âœ… 1 Free Forever Scrapy Cloud Unit
âœ… Unlimited crawl time (Ø¨Ø¯ÙˆÙ† Ø­Ø¯ÙˆØ¯!)
âœ… 120-day data retention
âœ… Unlimited team members & projects
âœ… Unlimited requests
```

---

## ğŸš€ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø±ÙŠØ¹

### 1ï¸âƒ£ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¶

1. Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰: https://www.zyte.com/github-students/
2. Sign up Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GitHub Student account
3. Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Free Forever unit

---

### 2ï¸âƒ£ ØªØ«Ø¨ÙŠØª Scrapy

```bash
# Install Scrapy
pip install scrapy

# Ø£Ùˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pnpm Ù„Ù„Ù…Ø´Ø±ÙˆØ¹
pnpm add scrapy
```

---

### 3ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Scrapy Project

```bash
# Create new Scrapy project
scrapy startproject vendoor_scraper

# Navigate to project
cd vendoor_scraper

# Create spider
scrapy genspider vendoor ven-door.com
```

---

### 4ï¸âƒ£ Ø§Ø³ØªØ®Ø¯Ø§Ù… Spider Ø§Ù„Ø¬Ø§Ù‡Ø²

Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ù„Ù `scrapy-vendoor/vendoor_spider.py` Ø§Ù„Ù…ÙÙ†Ø´Ø£ ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:

```bash
# Run spider locally (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
scrapy runspider scrapy-vendoor/vendoor_spider.py

# Output: vendoor-products.json
```

---

## â˜ï¸ Deploy Ø¹Ù„Ù‰ Scrapy Cloud

### Setup

```bash
# Install shub (Scrapy Cloud CLI)
pip install shub

# Login
shub login

# Deploy
shub deploy
```

### Schedule Spider

```bash
# Run spider on cloud
shub schedule vendoor

# Schedule periodic runs (ÙƒÙ„ 6 Ø³Ø§Ø¹Ø§Øª)
shub schedule --periodic vendoor
```

---

## ğŸ¯ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª

### âœ… Ø£Ø³Ø±Ø¹ Ù…Ù† Puppeteer
- **Scrapy:** ~2 Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ù€ 41 ØµÙØ­Ø©
- **Puppeteer:** ~10-15 Ø¯Ù‚ÙŠÙ‚Ø©

### âœ… Ø£Ø®Ù ÙˆØ£ÙƒÙØ£
- Ù„Ø§ ÙŠØ­ØªØ§Ø¬ Chrome browser
- Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ RAM Ø£Ù‚Ù„ Ø¨ÙƒØ«ÙŠØ±
- Concurrent requests (16+ ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª)

### âœ… Built-in Features
- Auto retry on failure
- Data export (JSON, CSV, XML)
- Rate limiting
- Caching
- Middleware system

### âœ… Cloud Benefits
- No server needed
- Auto-scaling
- Monitoring dashboard
- API access
- Scheduled jobs

---

## ğŸ“Š Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: Scrapy vs Puppeteer

| Ø§Ù„Ù…ÙŠØ²Ø© | Scrapy + Zyte | Puppeteer |
|--------|--------------|-----------|
| **Ø§Ù„Ø³Ø±Ø¹Ø©** | âš¡âš¡âš¡âš¡âš¡ (2 Ø¯Ù‚ÙŠÙ‚Ø©) | âš¡âš¡ (10-15 Ø¯Ù‚ÙŠÙ‚Ø©) |
| **Ø§Ù„Ù…ÙˆØ§Ø±Ø¯** | ğŸ’¾ Ø®ÙÙŠÙ Ø¬Ø¯Ø§Ù‹ | ğŸ’¾ğŸ’¾ğŸ’¾ Ø«Ù‚ÙŠÙ„ |
| **Ø§Ù„ØªÙƒÙ„ÙØ©** | ğŸ†“ Ù…Ø¬Ø§Ù†ÙŠ Ù„Ù„Ø£Ø¨Ø¯ | ğŸ’° ÙŠØ­ØªØ§Ø¬ hosting |
| **Setup** | ğŸ”§ Ø¨Ø³ÙŠØ· | ğŸ”§ğŸ”§ Ù…Ø¹Ù‚Ø¯ |
| **Scheduling** | âœ… Built-in | âŒ ÙŠØ­ØªØ§Ø¬ GitHub Actions |
| **Monitoring** | âœ… Dashboard | âŒ ÙŠØ¯ÙˆÙŠ |
| **JavaScript** | âš ï¸ Limited | âœ… Full support |

---

## ğŸ¤” Ù…ØªÙ‰ ØªØ³ØªØ®Ø¯Ù… ScrapyØŸ

### Ø§Ø³ØªØ®Ø¯Ù… Scrapy Ø¥Ø°Ø§:
- âœ… Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù„Ø§ ÙŠØ¹ØªÙ…Ø¯ Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ø¹Ù„Ù‰ JavaScript
- âœ… ØªØ­ØªØ§Ø¬ Ø³Ø±Ø¹Ø© Ø¹Ø§Ù„ÙŠØ©
- âœ… ØªØ­ØªØ§Ø¬ scraping Ù…Ø³ØªÙ…Ø± ÙˆÙ…Ø¬Ø¯ÙˆÙ„
- âœ… ØªØ±ÙŠØ¯ Ø£Ù‚Ù„ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ù„Ù„Ù…ÙˆØ§Ø±Ø¯

### Ø§Ø³ØªØ®Ø¯Ù… Puppeteer Ø¥Ø°Ø§:
- âœ… Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙŠØ­ØªØ§Ø¬ JavaScript rendering
- âœ… ØªØ­ØªØ§Ø¬ ØªÙØ§Ø¹Ù„ Ù…Ø¹Ù‚Ø¯ (clicks, scrolling)
- âœ… ØªØ­ØªØ§Ø¬ screenshots
- âœ… Ven-door ÙŠØ¹ØªÙ…Ø¯ Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ø¹Ù„Ù‰ React/Vue

---

## ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ven-door

Ù„Ù†Ø±Ù‰ Ù‡Ù„ Ven-door ÙŠØ­ØªØ§Ø¬ Puppeteer ÙØ¹Ù„Ø§Ù‹:

```bash
# Test with simple HTTP request
curl -I https://ven-door.com/products-upload
```

**Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù€ HTML Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø¨Ø§Ø´Ø±Ø© â†’ Ø§Ø³ØªØ®Ø¯Ù… Scrapy**  
**Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù€ HTML ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡ Ø¨Ù€ JavaScript â†’ Ø§Ø³ØªØ®Ø¯Ù… Puppeteer**

---

## ğŸ’¡ Ø§Ù„Ø­Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ: Hybrid

Ø§Ø³ØªØ®Ø¯Ù… **ÙƒÙ„Ø§Ù‡Ù…Ø§**:

1. **Scrapy Ù„Ù€ lightweight scraping** (Ø³Ø±ÙŠØ¹ + Ù…Ø¬Ø§Ù†ÙŠ)
2. **Puppeteer Ù„Ù„Ù€ complex pages** (Ø¥Ø°Ø§ Ø§Ø­ØªØ¬Øª)

```python
# ÙÙŠ Scrapy spider
def parse(self, response):
    if response.css('.react-root'):
        # Use Puppeteer for this page
        yield scrapy.Request(
            url=response.url,
            callback=self.parse_with_puppeteer,
            meta={'playwright': True}
        )
    else:
        # Use Scrapy normally
        yield from self.parse_with_scrapy(response)
```

---

## ğŸš€ Quick Start Commands

```bash
# 1. Install
pip install scrapy shub

# 2. Test locally
scrapy runspider scrapy-vendoor/vendoor_spider.py

# 3. Deploy to cloud
shub login
shub deploy

# 4. Run on cloud
shub schedule vendoor

# 5. Schedule periodic
shub schedule --periodic vendoor --cron "0 */6 * * *"
```

---

## ğŸ“ˆ Architecture Ù…Ø¹ Zyte

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Zyte Scrapy Cloud (FREE)        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Vendoor Spider              â”‚  â”‚
â”‚  â”‚   - Runs every 6 hours        â”‚  â”‚
â”‚  â”‚   - Scrapes 41 pages          â”‚  â”‚
â”‚  â”‚   - ~2 minutes execution      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Webhook     â”‚
        â”‚  (Your API)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   MongoDB     â”‚
        â”‚   Appwrite    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Ø§Ù„Ø®Ù„Ø§ØµØ©

**Zyte + Scrapy:**
- âš¡ Ø£Ø³Ø±Ø¹ 5x Ù…Ù† Puppeteer
- ğŸ’° Ù…Ø¬Ø§Ù†ÙŠ Ù„Ù„Ø£Ø¨Ø¯
- ğŸ”„ Scheduling built-in
- ğŸ“Š Monitoring dashboard
- â˜ï¸ Cloud-based (Ø¨Ø¯ÙˆÙ† server)

**Ø§Ù„Ù‚Ø±Ø§Ø±:**
1. Ø¬Ø±Ù‘Ø¨ Scrapy Ø£ÙˆÙ„Ø§Ù‹
2. Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¹Ù…Ù„ Ø¨Ø³Ø¨Ø¨ JavaScript â†’ Ø§Ø³ØªØ®Ø¯Ù… Puppeteer
3. Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ø§Ù‡Ù…Ø§ (hybrid)

---

## ğŸ“ Next Steps

1. [ ] Claim Zyte offer Ù…Ù† GitHub Student Pack
2. [ ] Test vendoor_spider.py locally
3. [ ] Check if Ven-door needs JavaScript rendering
4. [ ] Deploy to Scrapy Cloud
5. [ ] Setup periodic scraping (every 6 hours)

---

**ğŸ’¡ Tip:** Scrapy Ø£Ø®Ù ÙˆØ£Ø³Ø±Ø¹ØŒ Ø¬Ø±Ù‘Ø¨Ù‡ Ø£ÙˆÙ„Ø§Ù‹! ğŸš€
